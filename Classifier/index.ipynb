{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Modules needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#to find features of test data\n",
    "import os\n",
    "import featurefinder\n",
    "#plot graphs module\n",
    "import matplotlib.pyplot as plt\n",
    "#Normalisation modules\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Classifier module\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Training Dataset with Features Extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrainingData = pd.read_csv('Data/Train_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Radius Nearest Neighbors Classification\n",
    "\n",
    "```\n",
    "Note: in iloc format is [intial row: last row, intial column : last column]\n",
    "```\n",
    "Split training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Task\n",
      "0       Lift\n",
      "1       Lift\n",
      "2       Lift\n",
      "3       Lift\n",
      "4       Lift\n",
      "...      ...\n",
      "1498  Rotate\n",
      "1499  Rotate\n",
      "1500  Rotate\n",
      "1501  Rotate\n",
      "1502  Rotate\n",
      "\n",
      "[1503 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\Python37\\lib\\site-packages\\pandas\\core\\indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "df = dfTrainingData.iloc[:,:-1]\n",
    "task = dfTrainingData.iloc[:,-1:]\n",
    "\n",
    "print(task)\n",
    "\n",
    "cols = [col for col in df.columns if col not in ['Acc_X-71-JM','Acc_Y-71-JM','Acc_Z-71-JM','Gyr_X-71-JM','Gyr_Y-71-JM','Gyr_Z-71-JM','Acc_X-77-JM','Acc_Y-77-JM','Acc_Z-77-JM','Gyr_X-77-JM','Gyr_Y-77-JM','Gyr_Z-77-JM','Acc_X-71-PN','Acc_Y-71-PN','Acc_Z-71-PN','Gyr_X-71-PN','Gyr_Y-71-PN','Gyr_Z-71-PN','Acc_X-77-PN','Acc_Y-77-PN','Acc_Z-77-PN','Gyr_X-77-PN','Gyr_Y-77-PN','Gyr_Z-77-PN']]\n",
    "features = df[cols]\n",
    "\n",
    "le = LabelEncoder()\n",
    "features.iloc[:,-1] = le.fit_transform(features.iloc[:,-1])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, task, test_size = 0.20)\n",
    "#We are performing a train test split on the dataset. We are providing the test size as 0.20, that means our training sample contains 320 training set and test sample contains 80 test set\n",
    "\n",
    "# 'Acc_X-71-JM','Acc_Y-71-JM','Acc_Z-71-JM','Gyr_X-71-JM','Gyr_Y-71-JM','Gyr_Z-71-JM','Acc_X-77-JM','Acc_Y-77-JM','Acc_Z-77-JM','Gyr_X-77-JM','Gyr_Y-77-JM','Gyr_Z-77-JM'\n",
    "# 'Acc_X-71-PN','Acc_Y-71-PN','Acc_Z-71-PN','Gyr_X-71-PN','Gyr_Y-71-PN','Gyr_Z-71-PN','Acc_X-77-PN','Acc_Y-77-PN','Acc_Z-77-PN','Gyr_X-77-PN','Gyr_Y-77-PN','Gyr_Z-77-PN'\n",
    "\n",
    "\n",
    "# print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Classifer Model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('norm', MinMaxScaler()),\n",
       "                ('model', RadiusNeighborsClassifier())])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the model\n",
    "model = RadiusNeighborsClassifier()\n",
    "\n",
    "# create pipeline\n",
    "pipeline = Pipeline(steps=[('norm', MinMaxScaler()),('model',model)])\n",
    "\n",
    "\n",
    "#fit model\n",
    "pipeline.fit(X_train,np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Testing Data and using classifer to predict Validation measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix is: [[52 22  0  8]\n",
      " [23 46  4  5]\n",
      " [ 5 14 49  3]\n",
      " [ 0  1  1 68]]\n",
      "Accuracy score is: 0.714286\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "correctMatch = 0\n",
    "incorrectMatch = 0\n",
    "\n",
    "incorrectMatchLift= 0\n",
    "incorrectMatchRnR = 0\n",
    "incorrectMatchSwing = 0 \n",
    "incorrectMatchRotate = 0\n",
    "\n",
    "\n",
    "# make a prediction\n",
    "yhat = pipeline.predict(X_test)\n",
    "\n",
    "# find confusion matrix\n",
    "cm = confusion_matrix(y_test, yhat)\n",
    "ac = accuracy_score(y_test,yhat)\n",
    "\n",
    "print('Confusion matrix is: %s' % cm)\n",
    "print('Accuracy score is: %f' % ac)\n",
    "\n",
    "\n",
    "\n",
    "# print('Test Number: %d' % i)\n",
    "# i = i + 1\n",
    "# summarize prediction\n",
    "# print('Predicted Class: %s' % yhat)\n",
    "# print('Actual Class: %s' % )\n",
    "\n",
    "# for folder in os.listdir(\"Data/Predict/\"):\n",
    "#     path = \"Data/Predict/\" + folder + \"/\"\n",
    "#     for file in os.listdir(path):\n",
    "#         pathfile = \"Data/Predict/\" + folder + \"/\"\n",
    "#         Stan_Dev_names_U, RMS_names_U, Entropy_names_U, JM_names_U, PN_names_U, Stan_Dev_values_U, RMS_values_U,Entropy_values_U, JM_values_U, PN_values_U,Stan_Dev_values_L, RMS_values_L,  Entropy_values_L, JM_values_L, PN_values_L,Stan_Dev_names_L,RMS_names_L, Entropy_names_L, JM_names_L, PN_names_L = featurefinder.FeatureFinder(file,pathfile)\n",
    "#         if (len(Stan_Dev_values_L) > 0 ):\n",
    "#             # F_Names = Stan_Dev_names_L + RMS_names_L + Entropy_names_L + JM_names_L + PN_names_L + Stan_Dev_names_U + RMS_names_U + Entropy_names_U + JM_names_U + PN_names_U\n",
    "#             # F_Values = Stan_Dev_values_L + RMS_values_L + Entropy_values_L + JM_values_L + PN_values_L + Stan_Dev_values_U + RMS_values_U + Entropy_values_U + JM_values_U + PN_values_U\n",
    "#             F_Names = Stan_Dev_names_L + RMS_names_L + Entropy_names_L  + Stan_Dev_names_U + RMS_names_U + Entropy_names_U\n",
    "#             F_Values = Stan_Dev_values_L + RMS_values_L + Entropy_values_L  + Stan_Dev_values_U + RMS_values_U + Entropy_values_U\n",
    "#             dfFeaturesTest =  pd.DataFrame([],columns=F_Names)\n",
    "#             dfFeaturesTest.loc[len(dfFeaturesTest)] = F_Values\n",
    "#             # make a prediction\n",
    "#             yhat = pipeline.predict(dfFeaturesTest)\n",
    "#             # print('Test Number: %d' % i)\n",
    "#             i = i + 1\n",
    "#             # # summarize prediction\n",
    "#             # print('Predicted Class: %s' % yhat)\n",
    "#             # print('Actual Class: %s' % folder)\n",
    "#             if (str(yhat)[2:-2] == str(folder)):\n",
    "#                 correctMatch = correctMatch + 1\n",
    "#             else:\n",
    "# from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "# ac = accuracy_score(y_test,y_pred)\n",
    "#                 incorrectMatch = incorrectMatch + 1\n",
    "#                 if folder == 'Lift':\n",
    "#                     incorrectMatchLift = incorrectMatchLift + 1\n",
    "#                 elif folder == 'R&r':\n",
    "#                     incorrectMatchRnR = incorrectMatchRnR + 1\n",
    "#                     print(\"IS R&R --> Thinks is %s\" % str(yhat)[2:-2])\n",
    "#                 elif folder == 'Rotate':\n",
    "#                     incorrectMatchRotate = incorrectMatchRotate + 1\n",
    "#                 elif folder == 'Swing':\n",
    "#                     incorrectMatchSwing = incorrectMatchSwing + 1\n",
    "#                 else:\n",
    "#                     pass\n",
    "#         else:\n",
    "#             pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Correct matches are : %d \" % correctMatch)\n",
    "# print(\"Incorrect matches are : %d \" % incorrectMatch)\n",
    "# n = i + 1\n",
    "# Accuracy = (correctMatch/n)*100\n",
    "# print(\"Accuracy Percentage : %f \" % Accuracy)\n",
    "# print(\"Incorrect matches for Lift are : %d \" % incorrectMatchLift)\n",
    "# print(\"Incorrect matches for R&R are : %d \" % incorrectMatchRnR)\n",
    "# print(\"Incorrect matches for Swing are : %d \" % incorrectMatchSwing)\n",
    "# print(\"Incorrect matches for Rotate are : %d \" % incorrectMatchRotate)\n",
    "# # yat = \"['Lift']\"\n",
    "# print(yat[2:-2])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "232646cb2de524f0bc36ff9dca8c7a386b60fe5b1e35b35ac9c93c8a69681856"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
